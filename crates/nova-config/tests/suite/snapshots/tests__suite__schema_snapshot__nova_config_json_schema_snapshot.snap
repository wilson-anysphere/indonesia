---
source: crates/nova-config/tests/suite/schema_snapshot.rs
expression: schema
---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "NovaConfig",
  "description": "Top-level Nova configuration loaded from TOML.\n\nBuild tool integration can be configured via the `[build]` table: ```toml [build] # Default is `mode = \"auto\"` (use cached build metadata only; do not run build tools on cache misses). mode = \"on\" # \"off\" | \"auto\" | \"on\" timeout_ms = 120000\n\n[build.maven] mode = \"on\"\n\n[build.gradle] mode = \"on\" ```\n\nNote: the legacy alias `[build_integration]` is also accepted.\n\nLegacy compatibility: - `build.enabled = true|false` is treated as `build.mode = \"on\"|\"off\"`. - `build.maven.enabled = false` / `build.gradle.enabled = false` forces that tool `mode = \"off\"`.\n\nExtensions can be configured via the `[extensions]` table: ```toml [extensions] enabled = true wasm_paths = [\"./extensions\"] allow = [\"example.my_extension\"] deny = [\"example.bad_extension\"] wasm_memory_limit_bytes = 268435456 wasm_timeout_ms = 5000 ```",
  "type": "object",
  "allOf": [
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "provider": {
                "required": [
                  "kind"
                ],
                "properties": {
                  "kind": {
                    "enum": [
                      "open_ai",
                      "anthropic",
                      "gemini",
                      "azure_open_ai"
                    ]
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "api_key"
            ],
            "properties": {
              "api_key": {
                "type": "string",
                "minLength": 1,
                "pattern": "^\\S+$"
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "provider": {
                "required": [
                  "kind"
                ],
                "properties": {
                  "kind": {
                    "const": "azure_open_ai"
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "provider"
            ],
            "properties": {
              "provider": {
                "required": [
                  "azure_deployment"
                ],
                "properties": {
                  "azure_deployment": {
                    "type": "string",
                    "minLength": 1
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "provider": {
                "required": [
                  "kind"
                ],
                "properties": {
                  "kind": {
                    "const": "in_process_llama"
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "provider"
            ],
            "properties": {
              "provider": {
                "required": [
                  "in_process_llama"
                ],
                "properties": {
                  "in_process_llama": {
                    "$ref": "#/definitions/InProcessLlamaConfig"
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "provider": {
                "required": [
                  "kind"
                ],
                "properties": {
                  "kind": {
                    "enum": [
                      "open_ai",
                      "anthropic",
                      "gemini",
                      "azure_open_ai"
                    ]
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "privacy"
            ],
            "properties": {
              "privacy": {
                "required": [
                  "local_only"
                ],
                "properties": {
                  "local_only": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "privacy",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "privacy": {
                "required": [
                  "local_only"
                ],
                "properties": {
                  "local_only": {
                    "const": true
                  }
                }
              },
              "provider": {
                "required": [
                  "kind"
                ],
                "properties": {
                  "kind": {
                    "enum": [
                      "ollama",
                      "open_ai_compatible",
                      "http"
                    ]
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "properties": {
              "provider": {
                "properties": {
                  "url": {
                    "type": "string",
                    "pattern": "^https?://(localhost|127\\.0\\.0\\.1|\\[::1\\])(:[0-9]+)?(/|\\?|#|$)"
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "provider"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "provider": {
                "required": [
                  "kind",
                  "url"
                ],
                "properties": {
                  "kind": {
                    "enum": [
                      "ollama",
                      "open_ai_compatible",
                      "http"
                    ]
                  },
                  "url": {
                    "type": "string",
                    "not": {
                      "pattern": "^https?://(localhost|127\\.0\\.0\\.1|\\[::1\\])(:[0-9]+)?(/|\\?|#|$)"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "privacy"
            ],
            "properties": {
              "privacy": {
                "required": [
                  "local_only"
                ],
                "properties": {
                  "local_only": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "audit_log"
            ],
            "properties": {
              "audit_log": {
                "required": [
                  "enabled"
                ],
                "properties": {
                  "enabled": {
                    "const": true
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled"
            ],
            "properties": {
              "enabled": {
                "const": true
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "privacy"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "privacy": {
                "required": [
                  "allow_cloud_code_edits",
                  "local_only"
                ],
                "properties": {
                  "allow_cloud_code_edits": {
                    "const": true
                  },
                  "local_only": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "properties": {
              "privacy": {
                "anyOf": [
                  {
                    "required": [
                      "anonymize_identifiers"
                    ],
                    "properties": {
                      "anonymize_identifiers": {
                        "const": false
                      }
                    }
                  },
                  {
                    "required": [
                      "anonymize"
                    ],
                    "properties": {
                      "anonymize": {
                        "const": false
                      }
                    }
                  }
                ],
                "required": [
                  "allow_code_edits_without_anonymization"
                ],
                "properties": {
                  "allow_code_edits_without_anonymization": {
                    "const": true
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "privacy"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "privacy": {
                "required": [
                  "allow_code_edits_without_anonymization",
                  "local_only"
                ],
                "properties": {
                  "allow_code_edits_without_anonymization": {
                    "const": true
                  },
                  "local_only": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "properties": {
              "privacy": {
                "required": [
                  "allow_cloud_code_edits"
                ],
                "properties": {
                  "allow_cloud_code_edits": {
                    "const": true
                  }
                }
              }
            }
          }
        }
      }
    },
    {
      "if": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "required": [
              "enabled",
              "features",
              "privacy"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "features": {
                "required": [
                  "multi_token_completion"
                ],
                "properties": {
                  "multi_token_completion": {
                    "const": true
                  }
                }
              },
              "privacy": {
                "required": [
                  "local_only"
                ],
                "properties": {
                  "local_only": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      },
      "then": {
        "required": [
          "ai"
        ],
        "properties": {
          "ai": {
            "properties": {
              "privacy": {
                "anyOf": [
                  {
                    "required": [
                      "anonymize_identifiers"
                    ],
                    "properties": {
                      "anonymize_identifiers": {
                        "const": false
                      }
                    }
                  },
                  {
                    "required": [
                      "anonymize"
                    ],
                    "properties": {
                      "anonymize": {
                        "const": false
                      }
                    }
                  }
                ]
              }
            }
          }
        }
      }
    },
    {
      "not": {
        "required": [
          "build"
        ],
        "properties": {
          "build": {
            "required": [
              "enabled",
              "gradle",
              "maven"
            ],
            "properties": {
              "enabled": {
                "const": true
              },
              "gradle": {
                "required": [
                  "enabled"
                ],
                "properties": {
                  "enabled": {
                    "const": false
                  }
                }
              },
              "maven": {
                "required": [
                  "enabled"
                ],
                "properties": {
                  "enabled": {
                    "const": false
                  }
                }
              }
            }
          }
        }
      }
    }
  ],
  "properties": {
    "ai": {
      "description": "AI configuration (provider selection, privacy controls, embeddings, etc).",
      "default": {
        "api_key": null,
        "audit_log": {
          "enabled": false,
          "path": null
        },
        "cache_enabled": false,
        "cache_max_entries": 256,
        "cache_ttl_secs": 300,
        "embeddings": {
          "backend": "hash",
          "batch_size": 32,
          "enabled": false,
          "local_model": "all-MiniLM-L6-v2",
          "max_memory_bytes": 536870912,
          "model": null,
          "model_dir": ".nova/models/embeddings",
          "timeout_ms": null
        },
        "enabled": false,
        "features": {
          "code_actions": true,
          "code_review": true,
          "code_review_max_diff_chars": 50000,
          "completion_ranking": false,
          "explain_errors": true,
          "multi_token_completion": false,
          "semantic_search": false
        },
        "privacy": {
          "allow_cloud_code_edits": false,
          "allow_code_edits_without_anonymization": false,
          "anonymize_identifiers": null,
          "excluded_paths": [],
          "include_file_paths": false,
          "local_only": true,
          "redact_numeric_literals": null,
          "redact_patterns": [],
          "redact_sensitive_strings": null,
          "strip_or_redact_comments": null
        },
        "provider": {
          "azure_api_version": null,
          "azure_deployment": null,
          "concurrency": null,
          "in_process_llama": null,
          "kind": "ollama",
          "max_tokens": 1024,
          "model": "llama3",
          "retry_initial_backoff_ms": 200,
          "retry_max_backoff_ms": 2000,
          "retry_max_retries": 2,
          "temperature": null,
          "timeout_ms": 60000,
          "url": "http://localhost:11434/"
        },
        "timeouts": {
          "completion_ranking_ms": 20,
          "multi_token_completion_ms": 250
        }
      },
      "allOf": [
        {
          "$ref": "#/definitions/AiConfig"
        }
      ]
    },
    "build": {
      "description": "Controls build tool (Maven/Gradle) invocation for workspace metadata extraction.",
      "default": {
        "enabled": null,
        "gradle": {
          "enabled": null,
          "mode": null,
          "timeout_ms": null
        },
        "maven": {
          "enabled": null,
          "mode": null,
          "timeout_ms": null
        },
        "mode": "auto",
        "timeout_ms": 120000
      },
      "allOf": [
        {
          "$ref": "#/definitions/BuildIntegrationConfig"
        }
      ]
    },
    "extensions": {
      "description": "Workspace extensions (WASM bundles) configuration.",
      "default": {
        "allow": null,
        "deny": [],
        "enabled": true,
        "wasm_memory_limit_bytes": null,
        "wasm_paths": [],
        "wasm_timeout_ms": null
      },
      "allOf": [
        {
          "$ref": "#/definitions/ExtensionsConfig"
        }
      ]
    },
    "generated_sources": {
      "description": "Generated sources indexing and discovery configuration.",
      "default": {
        "additional_roots": [],
        "enabled": true,
        "override_roots": null
      },
      "allOf": [
        {
          "$ref": "#/definitions/GeneratedSourcesConfig"
        }
      ]
    },
    "jdk": {
      "description": "Workspace-level JDK override configuration.",
      "default": {
        "home": null,
        "release": null,
        "toolchains": []
      },
      "allOf": [
        {
          "$ref": "#/definitions/JdkConfig"
        }
      ]
    },
    "logging": {
      "description": "Global logging settings for Nova crates.",
      "default": {
        "buffer_lines": 2000,
        "file": null,
        "include_backtrace": false,
        "json": false,
        "level": "info",
        "stderr": true
      },
      "allOf": [
        {
          "$ref": "#/definitions/LoggingConfig"
        }
      ]
    },
    "memory": {
      "description": "Optional memory budgeting configuration (`nova-memory`).",
      "default": {
        "indexes_bytes": null,
        "other_bytes": null,
        "query_cache_bytes": null,
        "syntax_trees_bytes": null,
        "total_bytes": null,
        "type_info_bytes": null
      },
      "allOf": [
        {
          "$ref": "#/definitions/MemoryConfig"
        }
      ]
    }
  },
  "additionalProperties": false,
  "definitions": {
    "AiConfig": {
      "type": "object",
      "properties": {
        "api_key": {
          "description": "API key for the configured provider. This should never be included in bug report bundles.",
          "default": null,
          "writeOnly": true,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "audit_log": {
          "description": "Optional audit log configuration for AI prompts/model output.",
          "default": {
            "enabled": false,
            "path": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/AuditLogConfig"
            }
          ]
        },
        "cache_enabled": {
          "description": "Enable in-memory response caching for LLM calls made via `nova-ai`.\n\nDefaults to `false` (conservative): caching may retain model output in memory, so consumers must explicitly opt in.",
          "default": false,
          "type": "boolean"
        },
        "cache_max_entries": {
          "description": "Maximum number of cached responses to keep in memory.",
          "default": 256,
          "type": "integer",
          "format": "uint",
          "minimum": 1.0
        },
        "cache_ttl_secs": {
          "description": "Cache TTL in seconds.",
          "default": 300,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        },
        "embeddings": {
          "description": "Embeddings configuration used for semantic search and context building.",
          "default": {
            "backend": "hash",
            "batch_size": 32,
            "enabled": false,
            "local_model": "all-MiniLM-L6-v2",
            "max_memory_bytes": 536870912,
            "model": null,
            "model_dir": ".nova/models/embeddings",
            "timeout_ms": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/AiEmbeddingsConfig"
            }
          ]
        },
        "enabled": {
          "description": "Enables AI-assisted features. When enabled, **audit** logging may be enabled separately to capture prompts and model output (sanitized).",
          "default": false,
          "type": "boolean"
        },
        "features": {
          "description": "AI feature toggles (local augmentation + LLM-backed actions).",
          "default": {
            "code_actions": true,
            "code_review": true,
            "code_review_max_diff_chars": 50000,
            "completion_ranking": false,
            "explain_errors": true,
            "multi_token_completion": false,
            "semantic_search": false
          },
          "allOf": [
            {
              "$ref": "#/definitions/AiFeaturesConfig"
            }
          ]
        },
        "privacy": {
          "description": "Privacy controls and redaction behavior for AI requests.",
          "default": {
            "allow_cloud_code_edits": false,
            "allow_code_edits_without_anonymization": false,
            "anonymize_identifiers": null,
            "excluded_paths": [],
            "include_file_paths": false,
            "local_only": true,
            "redact_numeric_literals": null,
            "redact_patterns": [],
            "redact_sensitive_strings": null,
            "strip_or_redact_comments": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/AiPrivacyConfig"
            }
          ]
        },
        "provider": {
          "description": "Provider/backend configuration (kind, base URL, model, timeouts, etc).",
          "default": {
            "azure_api_version": null,
            "azure_deployment": null,
            "concurrency": null,
            "in_process_llama": null,
            "kind": "ollama",
            "max_tokens": 1024,
            "model": "llama3",
            "retry_initial_backoff_ms": 200,
            "retry_max_backoff_ms": 2000,
            "retry_max_retries": 2,
            "temperature": null,
            "timeout_ms": 60000,
            "url": "http://localhost:11434/"
          },
          "allOf": [
            {
              "$ref": "#/definitions/AiProviderConfig"
            }
          ]
        },
        "timeouts": {
          "description": "Timeouts for latency-sensitive AI operations.",
          "default": {
            "completion_ranking_ms": 20,
            "multi_token_completion_ms": 250
          },
          "allOf": [
            {
              "$ref": "#/definitions/AiTimeoutsConfig"
            }
          ]
        }
      },
      "additionalProperties": false
    },
    "AiEmbeddingsBackend": {
      "oneOf": [
        {
          "description": "Deterministic, fully-local embeddings based on the hashing trick.\n\nThis is the default to keep offline tests stable and to avoid requiring network access or model downloads.",
          "type": "string",
          "enum": [
            "hash"
          ]
        },
        {
          "description": "Provider-backed embeddings via the configured AI provider (`ai.provider.*`).",
          "type": "string",
          "enum": [
            "provider"
          ]
        },
        {
          "description": "In-process local neural embedding models.\n\nThis backend is supported when `nova-ai` is built with an appropriate local-embeddings feature (e.g. `embeddings-local`).",
          "type": "string",
          "enum": [
            "local"
          ]
        }
      ]
    },
    "AiEmbeddingsConfig": {
      "type": "object",
      "properties": {
        "backend": {
          "description": "Which embeddings backend to use.",
          "default": "hash",
          "allOf": [
            {
              "$ref": "#/definitions/AiEmbeddingsBackend"
            }
          ]
        },
        "batch_size": {
          "description": "Maximum batch size for embedding requests.",
          "default": 32,
          "type": "integer",
          "format": "uint",
          "minimum": 1.0
        },
        "enabled": {
          "description": "Enable embeddings for semantic search and context building.",
          "default": false,
          "type": "boolean"
        },
        "local_model": {
          "description": "Local embedding model identifier used when `backend = \"local\"`.\n\nThe set of supported values depends on the selected `nova-ai` local embedding implementation. When using `fastembed`, this corresponds to the built-in model IDs (e.g. `\"all-MiniLM-L6-v2\"` or `\"bge-small-en-v1.5\"`).",
          "default": "all-MiniLM-L6-v2",
          "type": "string",
          "minLength": 1
        },
        "max_memory_bytes": {
          "description": "Soft memory budget (in bytes) for embedding models / caches.\n\nAccepts either: - an integer byte count (e.g. `536870912`) - a human-friendly string (e.g. `\"512MiB\"`, `\"2G\"`)",
          "default": 536870912,
          "anyOf": [
            {
              "type": "integer",
              "format": "uint64",
              "minimum": 0.0
            },
            {
              "type": "string",
              "minLength": 1
            }
          ],
          "minimum": 1.0
        },
        "model": {
          "description": "Optional embedding model override when using provider-backed embeddings.\n\nWhen unset, Nova reuses `ai.provider.model`.\n\nNote: for Azure OpenAI (`ai.provider.kind = \"azure_open_ai\"`), Azure uses **deployments** instead of raw model names. In that case, `ai.embeddings.model` is treated as an embeddings deployment override (falling back to `ai.provider.azure_deployment` when unset).",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "model_dir": {
          "description": "Directory containing embedding model files / cache.",
          "default": ".nova/models/embeddings",
          "type": "string",
          "minLength": 1
        },
        "timeout_ms": {
          "description": "Optional timeout override (in milliseconds) when using provider-backed embeddings.\n\nWhen unset, Nova reuses `ai.provider.timeout_ms`.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "AiFeaturesConfig": {
      "type": "object",
      "properties": {
        "code_actions": {
          "description": "Enables LLM-backed code-editing actions (patch-based edits), such as:\n\n- \"Generate method body with AI\" (`nova/ai/generateMethodBody`) - \"Generate tests with AI\" (`nova/ai/generateTests`)\n\nDefaults to `true` so existing configs that set `ai.enabled=true` but do not mention `ai.features.code_actions` continue to offer code-editing actions.",
          "default": true,
          "type": "boolean"
        },
        "code_review": {
          "description": "Enables LLM-backed code review actions (for example: `nova ai review` when available).\n\nDefaults to `true` so existing configs that set `ai.enabled=true` but do not mention `ai.features.code_review` continue to allow code review actions.",
          "default": true,
          "type": "boolean"
        },
        "code_review_max_diff_chars": {
          "description": "Maximum number of diff characters included in AI code review prompts.\n\nLarge diffs can exceed LLM provider limits and increase latency/cost. When the diff exceeds this limit, Nova keeps the beginning and end of the diff and inserts a truncation marker indicating how much was omitted.",
          "default": 50000,
          "type": "integer",
          "format": "uint",
          "minimum": 1.0
        },
        "completion_ranking": {
          "description": "Enables AI-assisted completion re-ranking.",
          "default": false,
          "type": "boolean"
        },
        "explain_errors": {
          "description": "Enables the LLM-backed \"Explain this error\" action (`nova/ai/explainError`).\n\nDefaults to `true` so existing configs that set `ai.enabled=true` but do not mention `ai.features.explain_errors` continue to offer explain-error functionality.",
          "default": true,
          "type": "boolean"
        },
        "multi_token_completion": {
          "description": "Enables multi-token completion suggestions.",
          "default": false,
          "type": "boolean"
        },
        "semantic_search": {
          "description": "Enables semantic search-based features.",
          "default": false,
          "type": "boolean"
        }
      },
      "additionalProperties": false
    },
    "AiPrivacyConfig": {
      "type": "object",
      "allOf": [
        {
          "not": {
            "required": [
              "anonymize",
              "anonymize_identifiers"
            ]
          }
        }
      ],
      "properties": {
        "allow_cloud_code_edits": {
          "description": "Allow AI-assisted code edits (patches / file modifications) when `local_only = false` (cloud mode).\n\nThis is intentionally opt-in because code-edit prompts typically include larger portions of source code and the resulting edits can directly modify project files.",
          "default": false,
          "type": "boolean"
        },
        "allow_code_edits_without_anonymization": {
          "description": "Allow AI-assisted code edits when anonymization is disabled.\n\nIn cloud mode (`local_only = false`), disabling anonymization means raw source identifiers will be sent to the provider. This flag is an additional opt-in to avoid accidental leakage.",
          "default": false,
          "type": "boolean"
        },
        "anonymize": {
          "description": "Deprecated alias for `ai.privacy.anonymize_identifiers`.",
          "default": null,
          "deprecated": true,
          "type": [
            "boolean",
            "null"
          ]
        },
        "anonymize_identifiers": {
          "description": "If unset, defaults to: - `false` when `local_only = true` - `true` when `local_only = false` (cloud mode)\n\nThis matches Nova's privacy philosophy: anonymize identifiers when sending code to a third-party, but avoid needless transformations when everything stays local.\n\nBackwards compatibility: `ai.privacy.anonymize` is accepted as an alias for this field.",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        },
        "excluded_paths": {
          "description": "Glob patterns for file paths that must never be sent to the LLM.",
          "default": [],
          "type": "array",
          "items": {
            "type": "string",
            "minLength": 1
          }
        },
        "include_file_paths": {
          "description": "Allow including file system paths (file names, workspace-relative paths, or absolute paths) in prompts/context sent to the LLM.\n\nThis is a **high-sensitivity** setting: file paths can leak user names, organization names, internal directory structure, and other metadata. The safe default is `false`.\n\nNote: `ai.privacy.excluded_paths` is still enforced regardless of this flag. Excluded files are omitted from prompts, and Nova avoids attaching file path metadata for excluded files.",
          "default": false,
          "type": "boolean"
        },
        "local_only": {
          "description": "If true, Nova will not use any cloud providers. This is the recommended setting for privacy-sensitive environments.",
          "default": true,
          "type": "boolean"
        },
        "redact_numeric_literals": {
          "description": "Redact suspiciously long numeric literals (IDs / hashes) before sending code to an AI provider.\n\nIf unset, defaults to: - `false` when `local_only = true` (unless identifier anonymization is explicitly enabled) - `true` when `local_only = false` (cloud mode)",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        },
        "redact_patterns": {
          "description": "Regex patterns to redact from any text that will be sent to the LLM.",
          "default": [],
          "type": "array",
          "items": {
            "type": "string",
            "minLength": 1
          }
        },
        "redact_sensitive_strings": {
          "description": "Redact suspicious string literals (API keys, tokens, passwords) before sending code to an AI provider.\n\nIf unset, defaults to: - `false` when `local_only = true` (unless identifier anonymization is explicitly enabled) - `true` when `local_only = false` (cloud mode)",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        },
        "strip_or_redact_comments": {
          "description": "Strip or redact comment bodies before sending code to an AI provider.\n\nIf unset, defaults to: - `false` when `local_only = true` (unless identifier anonymization is explicitly enabled) - `true` when `local_only = false` (cloud mode)",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        }
      },
      "additionalProperties": false
    },
    "AiProviderConfig": {
      "type": "object",
      "properties": {
        "azure_api_version": {
          "description": "Azure OpenAI API version (e.g. `2024-02-01`).\n\nIf unset, Nova defaults to `2024-02-01`.",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "azure_deployment": {
          "description": "Azure OpenAI deployment name.\n\nRequired when `kind = \"azure_open_ai\"`.",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "concurrency": {
          "description": "Maximum number of concurrent requests Nova will make to the backend.\n\nIf unset, defaults to: - `1` for [`AiProviderKind::InProcessLlama`] - `4` for HTTP providers",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint",
          "minimum": 1.0
        },
        "in_process_llama": {
          "description": "Configuration for in-process inference when `kind = \"in_process_llama\"`.",
          "default": null,
          "anyOf": [
            {
              "$ref": "#/definitions/InProcessLlamaConfig"
            },
            {
              "type": "null"
            }
          ]
        },
        "kind": {
          "description": "Which backend implementation to use.",
          "default": "ollama",
          "allOf": [
            {
              "$ref": "#/definitions/AiProviderKind"
            }
          ]
        },
        "max_tokens": {
          "description": "Default max tokens for responses.",
          "default": 1024,
          "type": "integer",
          "format": "uint32",
          "minimum": 1.0
        },
        "model": {
          "description": "Default model name.",
          "default": "llama3",
          "type": "string",
          "minLength": 1
        },
        "retry_initial_backoff_ms": {
          "description": "Initial exponential backoff delay between retries (in milliseconds).",
          "default": 200,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        },
        "retry_max_backoff_ms": {
          "description": "Maximum exponential backoff delay between retries (in milliseconds).",
          "default": 2000,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        },
        "retry_max_retries": {
          "description": "Maximum number of retries for failed LLM requests.\n\nSet to `0` to disable retries entirely (useful for latency-sensitive environments).",
          "default": 2,
          "type": "integer",
          "format": "uint",
          "minimum": 0.0
        },
        "temperature": {
          "description": "Optional default sampling temperature applied to chat requests.\n\nWhen unset, Nova omits the `temperature` field entirely and the provider's default is used (often `1.0`).",
          "default": null,
          "type": [
            "number",
            "null"
          ],
          "format": "float",
          "minimum": 0.0
        },
        "timeout_ms": {
          "description": "Per-request timeout.",
          "default": 60000,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        },
        "url": {
          "description": "Base URL for the provider.\n\nExamples: - Ollama: `http://localhost:11434` - OpenAI-compatible (vLLM, llama.cpp server): `http://localhost:8000/v1` - OpenAI: `https://api.openai.com/v1` - Anthropic: `https://api.anthropic.com` - Gemini: `https://generativelanguage.googleapis.com` - Azure OpenAI: `https://{resource}.openai.azure.com`",
          "default": "http://localhost:11434/",
          "type": "string",
          "format": "uri",
          "pattern": "^https?://"
        }
      },
      "additionalProperties": false
    },
    "AiProviderKind": {
      "oneOf": [
        {
          "description": "Ollama HTTP API (e.g. http://localhost:11434)",
          "type": "string",
          "enum": [
            "ollama"
          ]
        },
        {
          "description": "OpenAI-compatible endpoints (e.g. vLLM, llama.cpp server, etc.)",
          "type": "string",
          "enum": [
            "open_ai_compatible"
          ]
        },
        {
          "description": "In-process local inference using a GGUF model file (llama.cpp).",
          "type": "string",
          "enum": [
            "in_process_llama"
          ]
        },
        {
          "description": "OpenAI's public API (https://api.openai.com). Requires `ai.api_key`.",
          "type": "string",
          "enum": [
            "open_ai"
          ]
        },
        {
          "description": "Anthropic Messages API (https://api.anthropic.com). Requires `ai.api_key`.",
          "type": "string",
          "enum": [
            "anthropic"
          ]
        },
        {
          "description": "Google Gemini Generative Language API (https://generativelanguage.googleapis.com). Requires `ai.api_key`.",
          "type": "string",
          "enum": [
            "gemini"
          ]
        },
        {
          "description": "Azure OpenAI. Requires `ai.api_key` and `ai.provider.azure_deployment`.",
          "type": "string",
          "enum": [
            "azure_open_ai"
          ]
        },
        {
          "description": "A simple JSON-over-HTTP API (useful for proxies and tests).\n\nNon-streaming request body: `{ \"model\": \"...\", \"prompt\": \"...\", \"max_tokens\": 123, \"temperature\": 0.2 }`\n\nNon-streaming response body: `{ \"completion\": \"...\" }`\n\nStreaming (`chat_stream()`) request body: `{ \"stream\": true, \"model\": \"...\", \"prompt\": \"...\", \"max_tokens\": 123, \"temperature\": 0.2 }`\n\nStreaming response (optional): providers may reply using Server-Sent Events (SSE) with\n`Content-Type: text/event-stream`.\n\nEach chunk is emitted as:\n`data: {\"completion\":\"...\"}`\n\nThe stream terminates with:\n`data: [DONE]`\n\nFallback: if the response is not SSE, Nova reads a single JSON response body\n(`{ \"completion\": \"...\" }`) and yields it as one chunk.",
          "type": "string",
          "enum": [
            "http"
          ]
        }
      ]
    },
    "AiTimeoutsConfig": {
      "type": "object",
      "properties": {
        "completion_ranking_ms": {
          "description": "Timeout for completion ranking requests.",
          "default": 20,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        },
        "multi_token_completion_ms": {
          "description": "Timeout for multi-token completion requests.",
          "default": 250,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "AuditLogConfig": {
      "type": "object",
      "properties": {
        "enabled": {
          "description": "Enable writing AI audit events (prompts / model output) to a dedicated log file.",
          "default": false,
          "type": "boolean"
        },
        "path": {
          "description": "Optional path for the audit log file.\n\nIf unset, defaults to `$TMPDIR/nova-ai-audit.log` at runtime.",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        }
      },
      "additionalProperties": false
    },
    "BuildIntegrationConfig": {
      "type": "object",
      "properties": {
        "enabled": {
          "description": "Deprecated legacy toggle for build tool integration.\n\nWhen set: - `true` is treated as `mode = \"on\"` - `false` is treated as `mode = \"off\"`\n\nPrefer `mode` for full control including the cache-only default (`auto`).",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        },
        "gradle": {
          "description": "Optional Gradle-specific overrides.",
          "default": {
            "enabled": null,
            "mode": null,
            "timeout_ms": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/BuildIntegrationToolConfig"
            }
          ]
        },
        "maven": {
          "description": "Optional Maven-specific overrides.",
          "default": {
            "enabled": null,
            "mode": null,
            "timeout_ms": null
          },
          "allOf": [
            {
              "$ref": "#/definitions/BuildIntegrationToolConfig"
            }
          ]
        },
        "mode": {
          "description": "Default build integration behavior for Maven/Gradle.",
          "default": "auto",
          "allOf": [
            {
              "$ref": "#/definitions/BuildIntegrationMode"
            }
          ]
        },
        "timeout_ms": {
          "description": "Timeout applied to build-tool metadata extraction commands (in milliseconds).",
          "default": 120000,
          "type": "integer",
          "format": "uint64",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "BuildIntegrationMode": {
      "description": "Controls whether Nova will invoke external build tools (Maven/Gradle) to extract build metadata (compile classpaths, source roots, language level, etc).",
      "oneOf": [
        {
          "description": "Never invoke external build tools. Nova relies on heuristic project loading (`nova-project`) and any user-specified overrides.",
          "type": "string",
          "enum": [
            "off"
          ]
        },
        {
          "description": "Use cached build metadata if available, but do not invoke build tools on cache misses.\n\nThis is the default to avoid surprising slow startup costs or build tool downloads.",
          "type": "string",
          "enum": [
            "auto"
          ]
        },
        {
          "description": "Invoke build tools on workspace load (and build file changes) to obtain accurate metadata.",
          "type": "string",
          "enum": [
            "on"
          ]
        }
      ]
    },
    "BuildIntegrationToolConfig": {
      "type": "object",
      "properties": {
        "enabled": {
          "description": "Deprecated legacy toggle for this specific build tool.\n\nWhen set to `false`, this tool is treated as `mode = \"off\"` regardless of global mode.\n\nPrefer `mode` for full control.",
          "default": null,
          "type": [
            "boolean",
            "null"
          ]
        },
        "mode": {
          "description": "Optional override for this build tool. When unset, `build.mode` is used.",
          "default": null,
          "anyOf": [
            {
              "$ref": "#/definitions/BuildIntegrationMode"
            },
            {
              "type": "null"
            }
          ]
        },
        "timeout_ms": {
          "description": "Optional timeout override for this build tool (in milliseconds).\n\nWhen unset, `build.timeout_ms` is used.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "ExtensionsConfig": {
      "type": "object",
      "properties": {
        "allow": {
          "description": "If set, only extensions with an id in this list will be loaded.",
          "default": null,
          "type": [
            "array",
            "null"
          ],
          "items": {
            "type": "string",
            "minLength": 1
          },
          "minItems": 1
        },
        "deny": {
          "description": "Extensions with an id in this list will never be loaded.",
          "default": [],
          "type": "array",
          "items": {
            "type": "string",
            "minLength": 1
          }
        },
        "enabled": {
          "description": "Whether extensions are enabled.",
          "default": true,
          "type": "boolean"
        },
        "wasm_memory_limit_bytes": {
          "description": "Optional upper bound for WASM extension linear memory (in bytes).\n\nWhen set, the runtime uses the *minimum* of this value and the per-plugin default. If unset, the per-plugin default applies.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 1.0
        },
        "wasm_paths": {
          "description": "Directories searched for extension bundles.\n\nEach directory is scanned for extension bundle folders containing a `nova-ext.toml` manifest.",
          "default": [],
          "type": "array",
          "items": {
            "type": "string",
            "minLength": 1
          }
        },
        "wasm_timeout_ms": {
          "description": "Optional upper bound for WASM extension execution timeouts (in milliseconds).\n\nWhen set, the runtime uses the *minimum* of this value and the per-plugin default. If unset, the per-plugin default applies.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "GeneratedSourcesConfig": {
      "type": "object",
      "properties": {
        "additional_roots": {
          "description": "Additional generated roots (relative to project root unless absolute).",
          "default": [],
          "type": "array",
          "items": {
            "type": "string",
            "minLength": 1
          }
        },
        "enabled": {
          "description": "Whether generated sources should be indexed and participate in resolution.",
          "default": true,
          "type": "boolean"
        },
        "override_roots": {
          "description": "If set, replaces default discovery entirely.",
          "default": null,
          "type": [
            "array",
            "null"
          ],
          "items": {
            "type": "string",
            "minLength": 1
          },
          "minItems": 1
        }
      },
      "additionalProperties": false
    },
    "InProcessLlamaConfig": {
      "type": "object",
      "required": [
        "model_path"
      ],
      "properties": {
        "context_size": {
          "description": "Context window size (`n_ctx`) used for inference.\n\nLarger values increase memory usage roughly linearly.",
          "default": 4096,
          "type": "integer",
          "format": "uint",
          "maximum": 8192.0,
          "minimum": 1.0
        },
        "gpu_layers": {
          "description": "Number of layers to offload to GPU (if supported by the build).\n\nA value of `0` disables GPU offload.",
          "default": 0,
          "type": "integer",
          "format": "uint32",
          "minimum": 0.0
        },
        "model_path": {
          "description": "Path to a GGUF model file on disk.",
          "type": "string",
          "minLength": 1
        },
        "temperature": {
          "description": "Sampling temperature.",
          "default": 0.20000000298023224,
          "type": "number",
          "format": "float",
          "minimum": 0.0
        },
        "threads": {
          "description": "Number of CPU threads to use (`n_threads`).\n\nIf unset or set to `0`, the backend will use the available parallelism.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint",
          "minimum": 0.0
        },
        "top_p": {
          "description": "Nucleus sampling probability.",
          "default": 0.949999988079071,
          "type": "number",
          "format": "float",
          "maximum": 1.0,
          "minimum": 0.0
        }
      },
      "additionalProperties": false
    },
    "JdkConfig": {
      "type": "object",
      "allOf": [
        {
          "not": {
            "required": [
              "home",
              "jdk_home"
            ]
          }
        },
        {
          "not": {
            "required": [
              "release",
              "target_release"
            ]
          }
        }
      ],
      "properties": {
        "home": {
          "description": "Optional override for the JDK installation to use.\n\nWhen set, JDK discovery will use this path instead of searching `JAVA_HOME` or `java` on `PATH`.",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "jdk_home": {
          "description": "Deprecated alias for `jdk.home`.",
          "default": null,
          "deprecated": true,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "release": {
          "description": "Default Java feature release used for `--release`-style API selection when callers don't provide one explicitly.",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint16",
          "minimum": 1.0
        },
        "target_release": {
          "description": "Deprecated alias for `jdk.release`.",
          "default": null,
          "deprecated": true,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint16",
          "minimum": 1.0
        },
        "toolchains": {
          "description": "Optional per-`--release` toolchains.",
          "default": [],
          "type": "array",
          "items": {
            "$ref": "#/definitions/JdkToolchainConfig"
          }
        }
      },
      "additionalProperties": false
    },
    "JdkToolchainConfig": {
      "type": "object",
      "required": [
        "home",
        "release"
      ],
      "properties": {
        "home": {
          "description": "Root directory of the JDK installation to use for this release.",
          "type": "string",
          "minLength": 1
        },
        "release": {
          "description": "Java feature release associated with this toolchain (e.g. 8, 17, 21).",
          "type": "integer",
          "format": "uint16",
          "minimum": 1.0
        }
      },
      "additionalProperties": false
    },
    "LoggingConfig": {
      "type": "object",
      "properties": {
        "buffer_lines": {
          "description": "Number of log lines kept in memory for bug reports.",
          "default": 2000,
          "type": "integer",
          "format": "uint",
          "minimum": 1.0
        },
        "file": {
          "description": "Append logs to the given file path (in addition to the in-memory buffer).\n\nIf the file cannot be opened, file logging is disabled while other sinks remain active.",
          "default": null,
          "type": [
            "string",
            "null"
          ],
          "minLength": 1
        },
        "include_backtrace": {
          "description": "Capture and include backtraces in panic reports.",
          "default": false,
          "type": "boolean"
        },
        "json": {
          "description": "Emit logs in JSON format.",
          "default": false,
          "type": "boolean"
        },
        "level": {
          "description": "Logging level for all Nova crates.",
          "default": "info",
          "type": "string"
        },
        "stderr": {
          "description": "Mirror logs to stderr (in addition to the in-memory buffer).\n\nDefaults to enabled so running Nova binaries outside an editor still produces real-time logs.",
          "default": true,
          "type": "boolean"
        }
      },
      "additionalProperties": false
    },
    "MemoryConfig": {
      "description": "Optional configuration for Nova's in-process memory budgets (`nova-memory`).",
      "type": "object",
      "properties": {
        "indexes_bytes": {
          "description": "Override the indexes category budget (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        },
        "other_bytes": {
          "description": "Override the \"other\" category budget (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        },
        "query_cache_bytes": {
          "description": "Override the query cache category budget (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        },
        "syntax_trees_bytes": {
          "description": "Override the syntax tree category budget (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        },
        "total_bytes": {
          "description": "Override the total memory budget for Nova's caches (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        },
        "type_info_bytes": {
          "description": "Override the type info category budget (in bytes).",
          "default": null,
          "type": [
            "integer",
            "null"
          ],
          "format": "uint64",
          "minimum": 0.0
        }
      },
      "additionalProperties": false
    }
  }
}
