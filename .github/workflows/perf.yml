name: perf

on:
  pull_request:
  push:
    branches:
      - main

jobs:
  perf:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      # Use a shared target dir so the baseline + current worktrees can reuse build artifacts.
      CARGO_TARGET_DIR: ${{ github.workspace }}/target
      # Improves CI triage when `nova` panics or `anyhow` captures a backtrace.
      RUST_BACKTRACE: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Rust cache
        uses: Swatinem/rust-cache@v2

      - name: Bench (baseline)
        if: github.event_name == 'pull_request'
        run: |
          set -euxo pipefail
          git worktree add /tmp/nova-perf-base ${{ github.event.pull_request.base.sha }}
          pushd /tmp/nova-perf-base
          cargo bench -p nova-core --bench critical_paths
          cargo bench -p nova-syntax --bench parse_java
          cargo bench -p nova-format --bench format
          cargo bench -p nova-refactor --bench refactor
          cargo bench -p nova-classpath --bench index
          cargo run -p nova-cli --release -- perf capture \
            --criterion-dir "${CARGO_TARGET_DIR}/criterion" \
            --out "${GITHUB_WORKSPACE}/perf-base.json"
          popd

      - name: Bench (current)
        run: |
          set -euxo pipefail
          cargo bench -p nova-core --bench critical_paths
          cargo bench -p nova-syntax --bench parse_java
          cargo bench -p nova-format --bench format
          cargo bench -p nova-refactor --bench refactor
          cargo bench -p nova-classpath --bench index
          cargo run -p nova-cli --release -- perf capture \
            --criterion-dir "${CARGO_TARGET_DIR}/criterion" \
            --out perf-current.json

      - name: Compare
        if: github.event_name == 'pull_request'
        run: |
          set -uox pipefail

          # Keep the existing behavior:
          # - write a markdown report and append it to `GITHUB_STEP_SUMMARY`
          # - exit nonzero when regressions exceed thresholds
          #
          # Additionally: write a machine-readable JSON report when supported.
          status=0

          # Determine which JSON output mode the CLI supports.
          help_file="$(mktemp)"
          cargo run -p nova-cli --release -- perf compare --help >"${help_file}"
          json_out_supported=0
          format_supported=0
          if grep -q -- '--json-out' "${help_file}"; then
            json_out_supported=1
          elif grep -Eq -- '^[[:space:]]+--format([[:space:]]|$)' "${help_file}"; then
            format_supported=1
          fi
          rm -f "${help_file}"

          if [ "${json_out_supported}" = "1" ]; then
            # Prefer a single invocation that emits both markdown + JSON.
            cargo run -p nova-cli --release -- perf compare \
              --baseline perf-base.json \
              --current perf-current.json \
              --config perf/thresholds.toml \
              --markdown-out perf-report.md \
              --json-out perf-report.json
            status=$?
          elif [ "${format_supported}" = "1" ]; then
            # Fallback for CLIs that only support structured output via `--format`.
            cargo run -p nova-cli --release -- perf compare \
              --baseline perf-base.json \
              --current perf-current.json \
              --config perf/thresholds.toml \
              --markdown-out perf-report.md
            status_md=$?

            cargo run -p nova-cli --release -- perf compare \
              --baseline perf-base.json \
              --current perf-current.json \
              --config perf/thresholds.toml \
              --format json > perf-report.json
            status_json=$?

            status=$status_md
            if [ "$status_json" -gt "$status" ]; then
              status=$status_json
            fi
          else
            # Backwards-compat: write a placeholder JSON file when the CLI can't emit JSON yet.
            cargo run -p nova-cli --release -- perf compare \
              --baseline perf-base.json \
              --current perf-current.json \
              --config perf/thresholds.toml \
              --markdown-out perf-report.md
            status=$?

            cat > perf-report.json <<'EOF'
          {"error":"nova perf compare did not emit JSON (no supported JSON output flags)"}
          EOF
          fi

          # If the CLI claims to support JSON output but didn't produce a file, fail loudly.
          if [ ! -f perf-report.json ]; then
            echo "perf compare did not produce perf-report.json" >&2
            status=2
          fi

          # Make sure the summary step doesn't fail if the report couldn't be written.
          if [ -f perf-report.md ]; then
            cat perf-report.md >> "${GITHUB_STEP_SUMMARY}"
          else
            echo "perf compare failed (exit ${status}) and did not produce perf-report.md" >> "${GITHUB_STEP_SUMMARY}"
          fi

          exit $status

      - name: Upload baseline (main)
        if: github.event_name == 'push'
        uses: actions/upload-artifact@v4
        with:
          # Stable artifact name so other workflows can download the latest `main` baseline.
          name: perf-baseline-main
          if-no-files-found: error
          path: perf-current.json

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-results
          if-no-files-found: ignore
          path: |
            perf-base.json
            perf-current.json
            perf-report.md
            perf-report.json
